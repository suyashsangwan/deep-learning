from keras.datasets import cifar10
import numpy as np
from __future__ import print_function
import keras
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Conv2D
from keras.layers import MaxPooling2D
from keras.layers import Dropout
from keras.layers import Flatten
import os


(trainingSet, trainingLabels), (testingSet, testingLabels) = cifar10.load_data()


save_dir = os.path.join(os.getcwd(), 'saved_models')
model_name = 'keras_cifar10_trained_model.h5'
print('Training data shape : ', trainingSet.shape, trainingLabels.shape)

print('Testing data shape : ', testingSet.shape, testingLabels.shape)

classes = np.unique(trainingLabels)
nClasses = len(classes)
print('Total number of outputs : ', nClasses)
nRows,nCols,nDims = trainingSet.shape[1:]
train_data = trainingSet.reshape(trainingSet.shape[0], nRows, nCols, nDims)
test_data = testingSet.reshape(testingSet.shape[0], nRows, nCols, nDims)
input_shape = (nRows, nCols, nDims)
train_data = train_data.astype('float32')/255.00
test_data = test_data.astype('float32')/255.00
trainingLabels_one_hot = keras.utils.to_categorical(trainingLabels)
testingLabels_one_hot = keras.utils.to_categorical(testingLabels)

def createModel():
    model = Sequential()
    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape))
    model.add(Conv2D(32, (3, 3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.25))
    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))
    model.add(Conv2D(64, (3, 3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.25))
    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))
    model.add(Conv2D(64, (3, 3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.25))
    model.add(Flatten())
    model.add(Dense(512, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(nClasses, activation='softmax'))
    return model

model1 = createModel()
batch_size = 256
epochs = 20
model1.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])

model1.summary()

history = model1.fit(train_data, trainingLabels_one_hot, batch_size=batch_size, epochs=epochs, verbose=1, 
                   validation_split=0.2,shuffle=True)
scores=model1.evaluate(test_data, testingLabels_one_hot,verbose=1)
print('Test loss:', scores[0])
print('Test accuracy:', scores[1])

from keras.preprocessing.image import ImageDataGenerator

model2 = createModel()

model2.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])

batch_size = 256
epochs = 50
datagen = ImageDataGenerator(
#         zoom_range=0.2, # randomly zoom into images
#         rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)
        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)
        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)
        horizontal_flip=True,  # randomly flip images
        vertical_flip=False)  # randomly flip images


# datagen.fit(train_data)

# Fit the model on the batches generated by datagen.flow().
history2 = model2.fit_generator(datagen.flow(train_data, trainingLabels_one_hot, batch_size=batch_size),
                              steps_per_epoch=int(np.ceil(train_data.shape[0] / float(batch_size))),
                              epochs=epochs,
                              validation_split=0.2,
                              workers=4)

scores2 = model2.evaluate(test_data, testingLabels_one_hot,verbose=1)
print('Test loss:', scores2[0])
print('Test accuracy:', scores2[1])

# Save model and weights
if not os.path.isdir(save_dir):
    os.makedirs(save_dir)
model_path = os.path.join(save_dir, model_name)
model.save(model_path)
print('Saved trained model at %s ' % model_path)
